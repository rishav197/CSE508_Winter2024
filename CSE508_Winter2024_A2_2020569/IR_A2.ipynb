{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishav197/CSE508_Winter2024/blob/main/CSE508_Winter2024_A2_2020569/IR_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnUIhsSXO54P"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ4iZkCEO_f8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl9kuV-uIOFk"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ycx6nmbEIo7a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from urllib.parse import urlparse\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import math\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_rLR8gOxOKto",
        "outputId": "a3dd93f0-896a-4482-b75f-1aa91783ebae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZWgqfIxvN2hT"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "odJK-HJcNxq3"
      },
      "outputs": [],
      "source": [
        "# Initialize NLTK components\n",
        "stop_words = set(stopwords.words('english'))\n",
        "porter = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeoJi2pVNorT"
      },
      "source": [
        "Loading the given dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OjsJBNOTO_ig",
        "outputId": "2d302102-a461-40c0-cefa-d9b0dbddb3c2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1109,\n        \"min\": 4,\n        \"max\": 3888,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          1023,\n          2801,\n          244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"['https://images-na.ssl-images-amazon.com/images/I/71vNRf0A+YL._SY88.jpg']\",\n          \"['https://images-na.ssl-images-amazon.com/images/I/61zFPF6hgrL._SY88.jpg']\",\n          \"['https://images-na.ssl-images-amazon.com/images/I/71aNT7H6QxL._SY88.jpg']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"I like this pedal very much so far. My favorite pedal was a Joyo and it didn't last long. It's in my junk pile. I hate the for the money thing. This delay pedal does a lot more than most one trick ponys out there. Money when you get into Chinese stuff is a gamble, I hope I get some time out of this Joyo because it just that great.\",\n          \"These are alot better than the Mahalo felt picks I've been using on my ukuleles. The Mahalos are soft, fat and flat, these are stiff, thinner and tapered, meaning they're easier to hold and play with and I get sharper sound. The 12 I got should last for quite some time, the Mahalos are showing more wear. Probably everyone should get some felt picks, very useful and alot of fun; these are really good ones.\",\n          \"Best strap lock system out there! -\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7e50ef0f-3577-4ca5-829b-0a972dcdc0cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Image</th>\n",
              "      <th>Review Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3452</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>Loving these vintage springs on my vintage str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1205</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>Works great as a guitar bench mat. Not rugged ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1708</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>We use these for everything from our acoustic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2078</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>Great price and good quality.  It didn't quite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>801</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>I bought this bass to split time as my primary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1265</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>Extremely impressed with this kit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1882</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>This is a great stereo reverb with plenty of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1547</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>I really like the simplicity of this bridge. I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1004</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>Great Product, but there is no warranty in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1306</td>\n",
              "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
              "      <td>This product is good and is used in profession...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e50ef0f-3577-4ca5-829b-0a972dcdc0cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e50ef0f-3577-4ca5-829b-0a972dcdc0cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e50ef0f-3577-4ca5-829b-0a972dcdc0cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7726bc03-2c5e-4452-9032-4ff860e9bbfa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7726bc03-2c5e-4452-9032-4ff860e9bbfa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7726bc03-2c5e-4452-9032-4ff860e9bbfa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       ID                                              Image  \\\n",
              "0    3452  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "1    1205  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "2    1708  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "3    2078  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "4     801  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "..    ...                                                ...   \n",
              "995  1265  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "996  1882  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "997  1547  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "998  1004  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "999  1306  ['https://images-na.ssl-images-amazon.com/imag...   \n",
              "\n",
              "                                           Review Text  \n",
              "0    Loving these vintage springs on my vintage str...  \n",
              "1    Works great as a guitar bench mat. Not rugged ...  \n",
              "2    We use these for everything from our acoustic ...  \n",
              "3    Great price and good quality.  It didn't quite...  \n",
              "4    I bought this bass to split time as my primary...  \n",
              "..                                                 ...  \n",
              "995                 Extremely impressed with this kit.  \n",
              "996  This is a great stereo reverb with plenty of c...  \n",
              "997  I really like the simplicity of this bridge. I...  \n",
              "998  Great Product, but there is no warranty in the...  \n",
              "999  This product is good and is used in profession...  \n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data = pd.read_csv(\"/content/drive/MyDrive/A2_Data.csv\")\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/A2_Data.csv\", skiprows=1, header=None, names=['ID', 'Image', 'Review Text'])\n",
        "data.rename(columns={\"Unnamed: 0\":\"ID\"}, inplace=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "56dKryKfO_lK",
        "outputId": "3c892e8f-32dc-4163-c737-2eefdb2373f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['ID', 'Image', 'Review Text'], dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfxcxuPMO_oE"
      },
      "source": [
        "**part-1: Image Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS6JB3n7I7gw"
      },
      "source": [
        "Resnet is used as a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U2nDBeymOdpm",
        "outputId": "a0bb055b-1d0c-412d-e734-1289147e55dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wCpPyOpOOjj8"
      },
      "outputs": [],
      "source": [
        "def preprocess_img(img):\n",
        "  if img is None:\n",
        "    print(\"Error: Empty image\")\n",
        "    return None\n",
        "\n",
        "  # Resize the image to 224x224\n",
        "  resized_img = cv2.resize(img, (224,224))\n",
        "\n",
        "  img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  #apply rotation\n",
        "  if np.random.rand()>0.5:\n",
        "    img = cv2.flip(img, 1)\n",
        "\n",
        "  brightness = np.random.uniform(0.5, 2.0)\n",
        "  exposure = np.random.uniform(0.5, 2.0)\n",
        "  img = cv2.convertScaleAbs(img, alpha=brightness, beta=0)\n",
        "  img = cv2.convertScaleAbs(img, alpha=exposure, beta=0)\n",
        "\n",
        "  #Normalize pixel vals of the image to the range from 0 to 1\n",
        "  img = img/255.0\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_PMeFkPdlkRn"
      },
      "outputs": [],
      "source": [
        "# method for extract features from images using ResNet50\n",
        "def extract_features(img):\n",
        "  x = np.expand_dims(img, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  features = resnet.predict(x)\n",
        "  return features.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SjUtb_5eue1v"
      },
      "outputs": [],
      "source": [
        "image_data = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3efauCiYOjec"
      },
      "outputs": [],
      "source": [
        "\n",
        "for idx, row in data.iterrows():\n",
        "  prod_id = row[\"ID\"]\n",
        "  # print(type(prod_id), prod_id)\n",
        "  img_urls = row[\"Image\"]\n",
        "  # print(img_urls)\n",
        "\n",
        "  lst_of_features = []\n",
        "\n",
        "  for idx, url in enumerate(eval(img_urls)):\n",
        "    img_data = requests.get(url).content\n",
        "    #Decode the image\n",
        "    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), -1)\n",
        "\n",
        "    if img is None:\n",
        "      print(\"Skipping invalid image: {}\".format(url))\n",
        "      continue\n",
        "\n",
        "    #preprocess the image\n",
        "    img = preprocess_img(img)\n",
        "\n",
        "    if img is None:\n",
        "      print(\"Skipping invalid image after preprocessing : {}\".format(url))\n",
        "      continue\n",
        "\n",
        "    img_features = extract_features(img)\n",
        "\n",
        "    lst_of_features.append({\n",
        "        \"image_features\":img_features,\n",
        "        \"image_url\":url\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "  if lst_of_features:\n",
        "    image_data[prod_id] = lst_of_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5YsEd4Fnfgw"
      },
      "outputs": [],
      "source": [
        "len(image_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XlcVE3nohnv"
      },
      "outputs": [],
      "source": [
        "with open('image_data.pkl', 'wb') as fptr:\n",
        "  pickle.dump(image_data, fptr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywiCajQ4nfUY"
      },
      "outputs": [],
      "source": [
        "with open('/content/image_data.pkl', 'rb') as fptr:\n",
        "  image_data = pickle.load(fptr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieQ7pt4fo6vk"
      },
      "outputs": [],
      "source": [
        "# image_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkNIRS1SOja6"
      },
      "source": [
        "**part-2: Text Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-6Zwmz5bjWW"
      },
      "source": [
        "a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo005-y0OjXj"
      },
      "outputs": [],
      "source": [
        "def preprocess_txt(text):\n",
        "  if type(text)==str:\n",
        "    #converting the text into lower-case\n",
        "    txt = text.lower()\n",
        "    # print(txt)\n",
        "\n",
        "    #tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # print(tokens)\n",
        "\n",
        "    #Removing puncts and stop words from tokens\n",
        "    processed_tokens = [word for word in tokens if word not in string.punctuation and word not in stop_words]\n",
        "    # print(processed_tokens)\n",
        "\n",
        "    #apply stemming\n",
        "    processed_tokens = [porter.stem(token) for token in processed_tokens]\n",
        "    # print(processed_tokens)\n",
        "\n",
        "    #apply lemmatization\n",
        "    processed_tokens = [lemmatizer.lemmatize(token) for token in processed_tokens]\n",
        "    # print(processed_tokens)\n",
        "\n",
        "    if processed_tokens:\n",
        "      #here we joining the processed tokens\n",
        "      processed_txt = \" \".join(processed_tokens)\n",
        "      return processed_txt\n",
        "    else:\n",
        "      return \"invalid text\"\n",
        "\n",
        "  else:\n",
        "    return \"invalid text\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c50XiTNYOjU7"
      },
      "outputs": [],
      "source": [
        "ans = preprocess_txt(\"This is a sample text for pre-processing.\")\n",
        "ans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8xfHCegPVLm"
      },
      "source": [
        "b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9lBwg7-Q0Fk"
      },
      "outputs": [],
      "source": [
        "#step-1: Calculating the term frequency (tf)\n",
        "def calc_tf(doc):\n",
        "  words = doc.split()\n",
        "  word_cnt = Counter(words)\n",
        "\n",
        "  tf = {}\n",
        "  for word in words:\n",
        "    val = word_cnt[word]/len(words)\n",
        "    tf[word]=val\n",
        "\n",
        "  return tf\n",
        "\n",
        "#step-2: Calculating the Inverse Document Fequency (tf-idf)\n",
        "def calc_idf(docs):\n",
        "  N = len(docs)\n",
        "  idf = {}\n",
        "  lst_of_words = []\n",
        "\n",
        "  for doc in docs:\n",
        "    for word in set(doc.split()):\n",
        "      lst_of_words.append(word)\n",
        "\n",
        "  print(lst_of_words)\n",
        "\n",
        "  for word in set(lst_of_words):\n",
        "    word_cnt = 0\n",
        "    for doc in docs:\n",
        "      if word in doc:\n",
        "        word_cnt+=1\n",
        "    idf[word] = math.log(N / (1+word_cnt))\n",
        "\n",
        "  return idf\n",
        "\n",
        "\n",
        "#Step-3: Calculate the TF-IDF score\n",
        "def calc_tfidf(docs):\n",
        "  tfidf = []\n",
        "  idf = calc_idf(docs)\n",
        "\n",
        "  for doc in docs:\n",
        "    tf = calc_tf(doc)\n",
        "    for word in tf:\n",
        "      tmp = {}\n",
        "      tmp[word] = tf[word]*idf[word]\n",
        "      tfidf.append(tmp)\n",
        "  return tfidf\n",
        "\n",
        "\n",
        "#Calculate the cosine similarity b/w two feature vectors\n",
        "def calc_cosine_similarity(f1, f2):\n",
        "  #Normalize feature vectors\n",
        "  f1_normalized = normalize(f1.reshape(1, -1))\n",
        "  f2_normalized = normalize(f2.reshape(1, -1))\n",
        "\n",
        "  if f1_normalized.shape[1] > f2_normalized.shape[1]:\n",
        "    f2_normalized = f2_normalized.T\n",
        "  else:\n",
        "    f1_normalized = f1_normalized.T\n",
        "\n",
        "  #Here's we calculating cosine similarity\n",
        "  return np.dot(f1_normalized, f2_normalized)\n",
        "calc_tf(\"thi sampl text pre-process\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNTZb6WaQ0CD"
      },
      "outputs": [],
      "source": [
        "#documents\n",
        "docs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFjkG060Qz-9"
      },
      "outputs": [],
      "source": [
        "for idx, row in data.iterrows():\n",
        "  # print(idx)\n",
        "  # print(row)\n",
        "\n",
        "  reivew_txt = row[\"Review Text\"]\n",
        "  # print(reivew_txt)\n",
        "\n",
        "  processed_review = preprocess_txt(reivew_txt)\n",
        "  # print(processed_review)\n",
        "\n",
        "  docs.append(processed_review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAv1XiD40viB"
      },
      "outputs": [],
      "source": [
        "print(len(docs), docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci98ruCCciVV"
      },
      "outputs": [],
      "source": [
        "#calculate the TF-IDF vectors for the documents\n",
        "tfidf_docs = calc_tfidf(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm-C0LVnciR1"
      },
      "outputs": [],
      "source": [
        "tfidf_data = {}\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "  review_txt = row[\"Review Text\"]\n",
        "  prod_id = row[\"ID\"]\n",
        "\n",
        "  lst_of_features = []\n",
        "  lst_of_features.append({\"review_txt\":review_txt, \"tfidf_score\":tfidf_docs[idx]})\n",
        "  tfidf_data[prod_id] = lst_of_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcr1XS-nciPf"
      },
      "outputs": [],
      "source": [
        "print(tfidf_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJorWEzGQJZc"
      },
      "source": [
        "Save extracted features and the TF-IDF score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd4F_8n7PSJS"
      },
      "outputs": [],
      "source": [
        "with open('tfidf_data.pkl', 'wb') as fptr:\n",
        "  pickle.dump(tfidf_data, fptr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxpiZfF3PSFz"
      },
      "outputs": [],
      "source": [
        "with open('/content/tfidf_data.pkl', 'rb') as f:\n",
        "  tfidf_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb44mmrAPSC6"
      },
      "outputs": [],
      "source": [
        "tfidf_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8T74gV3Q6l2"
      },
      "source": [
        "**part-3: Image and Text Retrieval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x97wdZBsRR7T"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_cs(v1, v2):\n",
        "  #apply padding on the smaller vector\n",
        "\n",
        "  diff = abs(len(v1) - len(v2))\n",
        "  if len(v1) > len(v2): #when v1 is greater than v2\n",
        "    v2 = np.pad(v2, (0, diff), \"constant\")\n",
        "  else: #when v2 is greater than v1\n",
        "    v1 = np.pad(v1, (0, diff), \"constant\")\n",
        "\n",
        "  #Reshape v1 and v2\n",
        "  v1 = v1.reshape(1, -1)\n",
        "  v2 = v2.reshape(1, -1)\n",
        "\n",
        "  #calculate the cosine similarity\n",
        "  return cosine_similarity(v1, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEiLR2Fk0juD"
      },
      "outputs": [],
      "source": [
        "input_image_url = 'https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg'\n",
        "input_review_text = 'I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtEGnYQ90jZq"
      },
      "outputs": [],
      "source": [
        "def get_img_features_from_url(url):\n",
        "  img_data = requests.get(url).content\n",
        "  img = cv2.imdecode(np.frombuffer(img_data, np.uint8), -1)\n",
        "  img_features = extract_features(img)\n",
        "\n",
        "  return img_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpQq7Ife-3lI"
      },
      "outputs": [],
      "source": [
        "# Extract features from the input image using VGG16 (you need to implement this part)\n",
        "input_image_features = get_img_features_from_url(input_image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVhPT0ye-vDe"
      },
      "outputs": [],
      "source": [
        "processed_review_txt = preprocess_txt(input_review_text)\n",
        "print(processed_review_txt)\n",
        "\n",
        "input_tfidf_score = calc_tfidf([processed_review_txt])\n",
        "print(input_tfidf_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jomRIYX4g2z8"
      },
      "source": [
        "Top3 three similar images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdpX0r4z-vAH"
      },
      "outputs": [],
      "source": [
        "lst_of_cs_img = [] #list of cosine similarities images\n",
        "\n",
        "for prod_id, images in image_data.items():\n",
        "  # print(prod_id)\n",
        "  # print(len(images), images)\n",
        "\n",
        "  for image in images:\n",
        "    score = get_cs(input_image_features, image[\"image_features\"])\n",
        "    lst_of_cs_img.append((prod_id, image[\"image_url\"], score))\n",
        "\n",
        "\n",
        "print(lst_of_cs_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DlhwWjuBVdV"
      },
      "outputs": [],
      "source": [
        "lst_of_cs_img.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "print(lst_of_cs_img)\n",
        "\n",
        "#top three docs with higher cosine similarity\n",
        "top3_similar_imgs = lst_of_cs_img[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxNTRR48YXVA"
      },
      "outputs": [],
      "source": [
        "top3_similar_imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmV0mTUyg9DS"
      },
      "source": [
        "Top3 three similar texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2l42swphXhL"
      },
      "outputs": [],
      "source": [
        "lst_of_cs_txt = [] #list of cosine similarities texts\n",
        "\n",
        "\n",
        "for prod_id, txt in tfidf_data.items():\n",
        "  # print(prod_id, txt)\n",
        "  for review_txt in txt:\n",
        "    score = get_cs(np.array(list(input_tfidf_score[0].values())), np.array(list(review_txt[\"tfidf_score\"].values())))\n",
        "    lst_of_cs_txt.append((prod_id, review_txt[\"review_txt\"], score))\n",
        "\n",
        "print(lst_of_cs_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bTtFCUyhXX0"
      },
      "outputs": [],
      "source": [
        "lst_of_cs_txt.sort(key=lambda x: x[2], reverse=True)\n",
        "print(lst_of_cs_txt)\n",
        "\n",
        "top3_similar_txts = lst_of_cs_txt[:3]\n",
        "print(top3_similar_txts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRNSZevamouZ"
      },
      "outputs": [],
      "source": [
        "top3_similar_txts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL_M2HIhv3GD"
      },
      "source": [
        "Composite Similarity Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np4OY96Bvz3U"
      },
      "outputs": [],
      "source": [
        "lst_of_composite_similarities = {}\n",
        "\n",
        "for e1 in lst_of_cs_txt:\n",
        "  # print(e1)\n",
        "  lst_of_docs = []\n",
        "  for e2 in lst_of_cs_img:\n",
        "    if e1[0]==e2[0]:\n",
        "      lst_of_docs.append({\"image_url\":e2[1], \"review_txt\":e1[1], \"combine_score\":(e1[2][0][0]+e2[2][0][0])/2})\n",
        "  lst_of_composite_similarities[e1[0]]=lst_of_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV991JFu1cNC"
      },
      "outputs": [],
      "source": [
        "lst_of_composite_similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_AJM5jqwByK"
      },
      "outputs": [],
      "source": [
        "lst_of_composite_similarities[170][0][\"combine_score\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NStyed1pYaWg"
      },
      "source": [
        "Image Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aXt0OOZaowM"
      },
      "outputs": [],
      "source": [
        "!pip install quo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtBfggE4ajWf"
      },
      "outputs": [],
      "source": [
        "from quo import echo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaP1RbfcYaTH"
      },
      "outputs": [],
      "source": [
        "print(\"-\"*80)\n",
        "echo(\"{}\".format(\"USING IMAGE RETRIEVAL\"), underline=True)\n",
        "\n",
        "\n",
        "\n",
        "for idx in range(len(top3_similar_imgs)):\n",
        "  # print(top3_similar_imgs[idx])\n",
        "  img = top3_similar_imgs[idx]\n",
        "  # print(img)\n",
        "  print(\"{}) \\033[1mImage URL:\\033[0m {}\".format(idx+1, img[1]))\n",
        "  for review in tfidf_data[img[0]]:\n",
        "    print(\"   \\033[1mReview:\\033[0m {}\".format(review[\"review_txt\"]))\n",
        "\n",
        "  print(\"   Cosine Similarity of images: {}\".format(img[2][0][0]))\n",
        "\n",
        "  for idx2 in range(len(lst_of_cs_txt)):\n",
        "    if lst_of_cs_txt[idx2][0] == img[0]:\n",
        "      print(\"   Cosine Similarity of text: {}\".format(lst_of_cs_txt[idx2][2][0][0]))\n",
        "      break\n",
        "  print(\"   Composite Similarity score: {}\".format(lst_of_composite_similarities[img[0]][0][\"combine_score\"]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzGRcNJcYaQu"
      },
      "source": [
        "Text Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXQ731wNheD6"
      },
      "outputs": [],
      "source": [
        "print(\"-\"*80)\n",
        "echo(\"{}\".format(\"USING TEXT RETRIEVAL\"), underline=True)\n",
        "\n",
        "\n",
        "for idx in range(len(top3_similar_txts)):\n",
        "  txt = top3_similar_txts[idx]\n",
        "  # print(txt)\n",
        "  print(\"{}) \\033[1mImage URL:\\033[0m\".format(idx+1), end=\"\")\n",
        "  print(\"[\", end=\"\")\n",
        "  count=1\n",
        "  for img in image_data[txt[0]]:\n",
        "    print(img[\"image_url\"], end=\"\")\n",
        "    if count<len(image_data[txt[0]]):\n",
        "      print(\", \", end=\"\")\n",
        "    count+=1\n",
        "  print(\"]\")\n",
        "  print(\"   \\033[1mReview:\\033[0m {}\".format(txt[1]))\n",
        "  for idx2 in range(len(lst_of_cs_img)):\n",
        "    if lst_of_cs_img[idx2][0]==txt[0]:\n",
        "      print(\"   Cosine Similarity of images: {}\".format(lst_of_cs_img[idx2][2][0][0]))\n",
        "      break\n",
        "  print(\"   Cosine Similarity of text: {}\".format(txt[2][0][0]))\n",
        "  print(\"   Composite Similarity score: {}\".format(lst_of_composite_similarities[txt[0]][0][\"combine_score\"]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPmMqKv5heAl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXYhasky0iW0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYTNBc7J0i5q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZzx8ssl0i2O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB1uOuqz7sI9P9+JtlMYvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}